# ğŸ¤– Agentic Corrective RAG System with LangGraph

This project demonstrates how to build an **Agentic Corrective Retrieval-Augmented Generation (RAG)** pipeline using [LangGraph](https://docs.langgraph.dev/). Inspired by the [Corrective RAG (CRAG) research paper](https://arxiv.org/pdf/2401.15884), this system introduces **self-corrective behavior** by detecting retrieval failures and invoking web search or fallback mechanisms.

---

## ğŸš€ Whatâ€™s Inside

### ğŸ§  What is Corrective RAG?
Traditional RAG systems rely heavily on vector search. If the vector DB doesnâ€™t return good results, the LLM often hallucinates. This notebook extends RAG by:
- **Monitoring the quality of retrieved documents**
- **Detecting knowledge gaps**
- **Triggering web search** or other agents when context is insufficient

### ğŸ•¸ï¸ What is Agentic RAG?
By modeling RAG steps as **agent-driven graph nodes**, each stage (retrieval, reasoning, verification, fallback) becomes autonomous and orchestrated through **LangGraph**, enabling:
- Custom logic at each node
- Memory and stateful decision-making
- Corrective flows with optional tool use

---

## ğŸ”§ Key Components

- âœ… **RAG pipeline (LangChain + LangGraph)**
- ğŸ” **Context Quality Checker Agent**
- ğŸŒ **Web Search Agent** (fallback mechanism)
- ğŸ“š **Document Retriever** (vector store + embeddings)
- ğŸ§  **LLM Answer Generator**
- ğŸ” **LangGraph Flow:** Define stepwise logic with fail-safe branches

---

## ğŸ§ª Use Case

User asks a question â†’  
ğŸ“¥ Retrieve documents â†’  
ğŸ“‰ Low relevance? â†’  
ğŸ” Trigger Web Search â†’  
âœ… Combine retrieved + web context â†’  
ğŸ§  Generate LLM response

---

## ğŸ“¦ Setup Instructions

1. **Install dependencies**

```bash
pip install langchain langgraph openai faiss-cpu
